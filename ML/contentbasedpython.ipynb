{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRihsljlAY66",
        "outputId": "75edc712-e7ab-4429-9112-677d84d93d29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17qtGFaF7IAG",
        "outputId": "8a799d3f-037e-4ac7-9163-50a76c253709"
      },
      "outputs": [],
      "source": [
        "#  Installation and Importing Libraries\n",
        "!pip install fastapi nest-asyncio pyngrok uvicorn ngrok\n",
        "from pyngrok import ngrok\n",
        "!ngrok authtoken <your-ngrok-token>\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pydantic\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn import linear_model\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, Body\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "from pandas import DataFrame, concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEiaugXs7Zzb"
      },
      "outputs": [],
      "source": [
        "# Reading User File\n",
        "u_cols =  ['user_id', 'firstName', 'lastName', 'phone']\n",
        "users = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ml-Journese/u.user', sep='|', names=u_cols, encoding='utf-8')\n",
        "n_users = users.shape[0]\n",
        "# Create a mapping from user_id to an integer index\n",
        "user_ids = users['user_id'].unique()\n",
        "user_id_to_index = {user_id: index for index, user_id in enumerate(user_ids)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhuAebOrzBUM"
      },
      "outputs": [],
      "source": [
        "# Reading Ratings File\n",
        "r_cols = ['user_id', 'place_id', 'rating']\n",
        "ratings_base = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ml-Journese/u.data', sep='|', names=r_cols, encoding='utf-8')\n",
        "ratings_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ml-Journese/u.data', sep='|', names=r_cols, encoding='utf-8')\n",
        "rate_train = ratings_base.values\n",
        "rate_test = ratings_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MLu2knZzMEk",
        "outputId": "1032dfb8-9976-48fc-fed3-5150befee9b5"
      },
      "outputs": [],
      "source": [
        "# Reading Items File\n",
        "i_cols = ['place id', 'place title' , 'Nghỉ dưỡng', 'Phong cảnh', 'Lịch sử', 'Mua sắm', 'Ẩm thực', 'Văn hoá', 'Phượt', 'Biển', 'Núi',\n",
        "          'Thiên nhiên', 'Sống ảo/Gen z', 'Nghệ thuật', 'Xanh', 'Phổ biến', 'Tham quan']\n",
        "items = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ml-Journese/u.item', sep='|', names=i_cols, encoding='utf-8')\n",
        "n_items = items.shape[0]\n",
        "X0 = items.values\n",
        "X_train_counts = X0[:, -15:]\n",
        "print(X_train_counts)\n",
        "transformer = TfidfTransformer(smooth_idf=True, norm ='l2')\n",
        "tfidf = transformer.fit_transform(X_train_counts.tolist()).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H99k-GxazL30"
      },
      "outputs": [],
      "source": [
        "# Function to Get Items Rated by User\n",
        "def get_items_rated_by_user(rate_matrix, user_id):\n",
        "    y = rate_matrix[:,0]\n",
        "    # Use the mapping to get the index corresponding to the user_id\n",
        "    ids = np.where(y == user_id)[0]\n",
        "    item_ids = rate_matrix[ids, 1]  # treat place_id as string\n",
        "    scores = rate_matrix[ids, 2]\n",
        "    return (item_ids, scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT1xrgpFzLo8",
        "outputId": "c9956760-71d0-4b6e-f62c-235c45a67a74"
      },
      "outputs": [],
      "source": [
        "# Training the Model\n",
        "d = tfidf.shape[1]\n",
        "W = np.zeros((d, n_users))\n",
        "b = np.zeros((1, n_users))\n",
        "place_ids = items['place id'].unique()\n",
        "place_id_to_index = {place_id: index for index, place_id in enumerate(place_ids)}\n",
        "for user_id in user_ids:\n",
        "    ids, scores = get_items_rated_by_user(rate_train, user_id)\n",
        "    if len(ids) == 0:  # Skip users with no ratings\n",
        "        continue\n",
        "    print(f\"user_id: {user_id}, ids: {ids}\")\n",
        "    clf = Ridge(alpha=0.01, fit_intercept  = True)\n",
        "    try:\n",
        "        indices = [place_id_to_index[place_id] for place_id in ids]\n",
        "        Xhat = tfidf[indices, :]\n",
        "    except IndexError:\n",
        "        print(f\"IndexError for user_id: {user_id}, ids: {ids}\")\n",
        "        break\n",
        "    clf.fit(Xhat, scores)\n",
        "    W[:, user_id_to_index[user_id]] = clf.coef_\n",
        "    b[0, user_id_to_index[user_id]] = clf.intercept_\n",
        "\n",
        "\n",
        "Yhat = tfidf.dot(W) + b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edGAPdvr2bz1"
      },
      "outputs": [],
      "source": [
        "#  Function to Recommend Places for User\n",
        "def recommend_places_for_user(user_id, n_recommendations=10):\n",
        "    if user_id not in user_id_to_index:\n",
        "        print('Invalid user_id')\n",
        "        return\n",
        "    user_index = user_id_to_index[user_id]\n",
        "    rated_item_ids, _ = get_items_rated_by_user(rate_train, user_id)\n",
        "    predicted_ratings = Yhat[:, user_index]\n",
        "    sorted_indices = np.argsort(predicted_ratings)[::-1]\n",
        "    unrated_sorted_indices = [i for i in sorted_indices if i not in rated_item_ids]\n",
        "    top_n_recommendations = unrated_sorted_indices[:n_recommendations]\n",
        "    return top_n_recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPytAzgu2tVT"
      },
      "outputs": [],
      "source": [
        "# FastAPI Setup\n",
        "app = FastAPI()\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "@app.get(\"/recommendations/{user_id}\")\n",
        "async def get_recommendations(user_id: str):\n",
        "    recommendations = recommend_places_for_user(user_id)\n",
        "    place_titles = [{'id': items.iloc[place_id]['place id'], 'title': items.iloc[place_id]['place title']} for place_id in recommendations]\n",
        "    return {\"user_id\": user_id, \"recommendations\": place_titles}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xkypSZby7T_"
      },
      "outputs": [],
      "source": [
        "# # API add place\n",
        "# # Define a Pydantic model for Place data\n",
        "class Place(BaseModel):\n",
        "    id: str\n",
        "    title: str\n",
        "    tags: list[str]\n",
        "\n",
        "@app.post(\"/places/\")\n",
        "async def create_or_update_place(place: Place = Body(...)):\n",
        "    global items\n",
        "    all_tags = ['Nghỉ dưỡng', 'Phong cảnh', 'Lịch sử', 'Mua sắm', 'Ẩm thực', 'Văn hoá', 'Phượt', 'Biển', 'Núi',\n",
        "                'Thiên nhiên', 'Sống ảo/Gen z', 'Nghệ thuật', 'Xanh', 'Phổ biến', 'Tham quan']\n",
        "    tag_values = [1 if tag in place.tags else 0 for tag in all_tags]\n",
        "    place_data = [place.id, place.title] + tag_values\n",
        "    if place.id in items['place id'].values:\n",
        "        # Update the existing place\n",
        "        items.loc[items['place id'] == place.id] = place_data\n",
        "        message = \"Place updated successfully!\"\n",
        "    else:\n",
        "        # Append the new place data to the items DataFrame\n",
        "        items = concat([items, DataFrame([place_data], columns=items.columns)], ignore_index=True)\n",
        "        message = \"Place created successfully!\"\n",
        "\n",
        "    # Update the item_id_to_index mapping\n",
        "    items.to_csv('/content/drive/MyDrive/Colab Notebooks/ml-Journese/u.item', sep='|', header=False, index=False)\n",
        "\n",
        "    # Update the tfidf array with the TF-IDF values of the new place\n",
        "    global tfidf\n",
        "    X0 = items.values\n",
        "    X_train_counts = X0[:, -15:]\n",
        "    transformer = TfidfTransformer(smooth_idf=True, norm ='l2')\n",
        "    tfidf = transformer.fit_transform(X_train_counts.tolist()).toarray()\n",
        "\n",
        "    # Retrain the model\n",
        "    global place_ids, place_id_to_index\n",
        "    place_ids = items['place id'].unique()\n",
        "    place_id_to_index = {place_id: index for index, place_id in enumerate(place_ids)}\n",
        "    d = tfidf.shape[1]\n",
        "    W = np.zeros((d, n_users))\n",
        "    b = np.zeros((1, n_users))\n",
        "    for user_id in user_ids:\n",
        "        ids, scores = get_items_rated_by_user(rate_train, user_id)\n",
        "        if len(ids) == 0:  # Skip users with no ratings\n",
        "            continue\n",
        "        print(f\"user_id: {user_id}, ids: {ids}\") \n",
        "        clf = Ridge(alpha=0.01, fit_intercept  = True)\n",
        "        try:\n",
        "            indices = [place_id_to_index[place_id] for place_id in ids]\n",
        "            Xhat = tfidf[indices, :]\n",
        "        except IndexError:\n",
        "            print(f\"IndexError for user_id: {user_id}, ids: {ids}\")\n",
        "            break\n",
        "        clf.fit(Xhat, scores)\n",
        "        W[:, user_id_to_index[user_id]] = clf.coef_\n",
        "        b[0, user_id_to_index[user_id]] = clf.intercept_\n",
        "\n",
        "    global Yhat\n",
        "    Yhat = tfidf.dot(W) + b\n",
        "    # Create a dictionary for the new place\n",
        "    place_dict = {\n",
        "        \"id\": place.id,\n",
        "        \"title\": place.title,\n",
        "        \"tags\": tag_values\n",
        "    }\n",
        "\n",
        "    return {\"message\": message, \"place\": place_dict}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SLaJ9-g4D5O"
      },
      "outputs": [],
      "source": [
        "# API add or update rating\n",
        "# Define a Pydantic model for Rating data\n",
        "class Rating(BaseModel):\n",
        "    user_id: str\n",
        "    place_id: str\n",
        "    rating: int\n",
        "\n",
        "@app.post(\"/ratings/\")\n",
        "async def update_rating(rating: Rating = Body(...)):\n",
        "    global ratings_base  # Declare ratings_base as global\n",
        "\n",
        "    # Check if the rating already exists\n",
        "    rating_exists = ((ratings_base['user_id'] == rating.user_id) & (ratings_base['place_id'] == rating.place_id)).any()\n",
        "\n",
        "    if rating_exists:\n",
        "        # If the rating exists, update it\n",
        "        ratings_base.loc[(ratings_base['user_id'] == rating.user_id) & (ratings_base['place_id'] == rating.place_id), 'rating'] = rating.rating\n",
        "    else:\n",
        "        # If the rating doesn't exist, create it\n",
        "\n",
        "        ratings_base = concat([ratings_base, DataFrame([rating.dict()])], ignore_index=True)\n",
        "\n",
        "    # Write the updated DataFrame to the file\n",
        "    ratings_base.to_csv('/content/drive/MyDrive/Colab Notebooks/ml-Journese/u.data', sep='|', header=False, index=False)\n",
        "    # Update rate_train\n",
        "    global rate_train\n",
        "    rate_train = ratings_base.values\n",
        "    # Retrain the model\n",
        "    global place_ids, place_id_to_index\n",
        "    place_ids = items['place id'].unique()\n",
        "    place_id_to_index = {place_id: index for index, place_id in enumerate(place_ids)}\n",
        "    d = tfidf.shape[1]\n",
        "    W = np.zeros((d, n_users))\n",
        "    b = np.zeros((1, n_users))\n",
        "    for user_id in user_ids:\n",
        "        ids, scores = get_items_rated_by_user(rate_train, user_id)\n",
        "        if len(ids) == 0:  # Skip users with no ratings\n",
        "            continue\n",
        "        print(f\"user_id: {user_id}, ids: {ids}\")\n",
        "        clf = Ridge(alpha=0.01, fit_intercept  = True)\n",
        "        try:\n",
        "            indices = [place_id_to_index[place_id] for place_id in ids]\n",
        "            Xhat = tfidf[indices, :]\n",
        "        except IndexError:\n",
        "            print(f\"IndexError for user_id: {user_id}, ids: {ids}\")\n",
        "            break\n",
        "        clf.fit(Xhat, scores)\n",
        "        W[:, user_id_to_index[user_id]] = clf.coef_\n",
        "        b[0, user_id_to_index[user_id]] = clf.intercept_\n",
        "\n",
        "    global Yhat\n",
        "    Yhat = tfidf.dot(W) + b\n",
        "\n",
        "    return {\"message\": \"Rating updated successfully!\", \"rating\": rating.dict()}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OBlg4urnXwI"
      },
      "outputs": [],
      "source": [
        "class User(BaseModel):\n",
        "    user_id: str\n",
        "    firstName: str\n",
        "    lastName: str\n",
        "    phone: str\n",
        "@app.post(\"/users/\")\n",
        "async def create_user(user: User = Body(...)):\n",
        "    global users, user_ids, user_id_to_index, n_users\n",
        "    users = concat([users, DataFrame([user.dict()])], ignore_index=True)\n",
        "    users.to_csv('/content/drive/MyDrive/Colab Notebooks/ml-Journese/u.user', sep='|', header=False, index=False)\n",
        "    # Update the user_id_to_index mapping\n",
        "    user_ids = users['user_id'].unique()\n",
        "    user_id_to_index = {user_id: index for index, user_id in enumerate(user_ids)}\n",
        "    n_users = users.shape[0]\n",
        "\n",
        "    # Retrain the model\n",
        "    d = tfidf.shape[1]\n",
        "    W = np.zeros((d, n_users))\n",
        "    b = np.zeros((1, n_users))\n",
        "    for user_id in user_ids:\n",
        "        ids, scores = get_items_rated_by_user(rate_train, user_id)\n",
        "        if len(ids) == 0:  # Skip users with no ratings\n",
        "            continue\n",
        "        clf = Ridge(alpha=0.01, fit_intercept  = True)\n",
        "        try:\n",
        "            Xhat = tfidf[ids, :]\n",
        "        except IndexError:\n",
        "            print(f\"IndexError for user_id: {user_id}, ids: {ids}\")\n",
        "            break\n",
        "        clf.fit(Xhat, scores)\n",
        "        W[:, user_id_to_index[user_id]] = clf.coef_\n",
        "        b[0, user_id_to_index[user_id]] = clf.intercept_\n",
        "\n",
        "    # Update Yhat globally\n",
        "    global Yhat\n",
        "    Yhat = tfidf.dot(W) + b\n",
        "    return {\"message\": \"User created successfully!\", \"user\": user}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blwqCDU-ChWM"
      },
      "outputs": [],
      "source": [
        "@app.get(\"/predictions/{user_id}\")\n",
        "async def get_predictions(user_id: str):\n",
        "      # Check if user_id is in the users DataFrame\n",
        "    if user_id not in users['user_id'].values:\n",
        "        raise HTTPException(status_code=400, detail=\"Invalid user_id\")\n",
        "\n",
        "    # Get the rated item ids and scores\n",
        "    rated_item_ids, rated_scores = get_items_rated_by_user(rate_train, user_id)\n",
        "\n",
        "    # Get the predicted ratings for the user\n",
        "    user_index = user_id_to_index[user_id]\n",
        "    predicted_ratings = Yhat[:, user_index]\n",
        "\n",
        "    # Prepare the response\n",
        "    predictions = []\n",
        "    for place_index, rating in enumerate(predicted_ratings):\n",
        "        place_id = items.iloc[place_index]['place id']\n",
        "        place_title = items.iloc[place_index]['place title']\n",
        "        if place_id in rated_item_ids:\n",
        "            true_rating_index = np.where(rated_item_ids == place_id)[0][0]\n",
        "            true_rating = rated_scores[true_rating_index]\n",
        "            predictions.append({\"Place\": place_title, \"True Rating\": true_rating})\n",
        "        else:\n",
        "            predictions.append({\"Place\": place_title, \"Predicted Rating\": rating})\n",
        "\n",
        "    return {\"user_id\": user_id, \"predictions\": predictions}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPVMCgxt2v1r",
        "outputId": "780bc27e-d5bf-49bd-ecae-67c90de0eb9a"
      },
      "outputs": [],
      "source": [
        "# Running the Server\n",
        "ngrok_tunnel = ngrok.connect(8000, \"http\", hostname=\"exotic-filly-publicly.ngrok-free.app\")\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
